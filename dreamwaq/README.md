# dreamwaq


https://github.com/curieuxjy/dreamwaq/assets/40867411/5dcea5c9-3ff3-469d-baa7-70f0852a0395

[ðŸŽ¥ 1080 Streaming Video in YouTube](https://youtu.be/5rwFcz-lerw)

## Index

- [Start Manual](https://github.com/curieuxjy/dreamwaq#start-manual): í”„ë¡œì íŠ¸ í™˜ê²½ ì„¤ì •ê³¼ ì‹¤í–‰ ë°©ë²•ì— ëŒ€í•œ ë‚´ìš© 
- [Main Code Structure](https://github.com/curieuxjy/dreamwaq#main-code-structure): í”„ë¡œì íŠ¸ ì£¼ìš” ì½”ë“œ ì„¤ëª… 
- [Result Graphs](https://github.com/curieuxjy/dreamwaq#result-graphs): í”„ë¡œì íŠ¸ í•™ìŠµ ê²°ê³¼ ê·¸ëž˜í”„
- [Result Motions](https://github.com/curieuxjy/dreamwaq#result-motions): í”„ë¡œì íŠ¸ í•™ìŠµ ê²°ê³¼ ë³´í–‰ ëª¨ì…˜ ì˜ìƒ(Video íŒŒíŠ¸ë³„ gif)

## Start Manual

### Start **w/o** this repository
> ì´ repositoryì™€ ìƒê´€ì—†ì´ êµ¬í˜„ í”„ë¡œì íŠ¸ ì´ˆê¸° ì…‹íŒ…ìž…ë‹ˆë‹¤.  ì´ repositoryë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì‹¤í–‰ í•˜ë ¤ë©´, ì•„ëž˜ w/ ì‹¤í–‰ ë‹¨ê³„ë¥¼ ì°¸ê³ í•´ì£¼ì„¸ìš”.  
1. IsaacGym ver.4 ì„¤ì¹˜
2. [rsl-rl](https://github.com/leggedrobotics/rsl_rl) githubì—ì„œ **zip**íŒŒì¼ë¡œ ë‹¤ìš´ë°›ì•„ì„œ ì„¤ì¹˜ `pip install -e .`
3. [legged-gym](https://github.com/leggedrobotics/legged_gym) githubì—ì„œ **zip**íŒŒì¼ë¡œ ë‹¤ìš´ë°›ì•„ì„œ ì„¤ì¹˜ `pip install -e .`
4. wandb ë“± ëª‡ê°€ì§€ ì‹¤í—˜ ë¡œê¹…ì— í•„ìš”í•œ ë¶€ë¶„ ìˆ˜ì •(ê°ìž ê³„ì •ìœ¼ë¡œ ë¡œê·¸ì¸í•´ì•¼ í•¨) 

### Start **w/** this repository
> ì´ repositoryë¥¼ ê¸°ë°˜ìœ¼ë¡œ í”„ë¡œì íŠ¸ë¥¼ ì‹œìž‘í•  ë•Œ ì•„ëž˜ì™€ ê°™ì´ ì§„í–‰í•´ì£¼ì„¸ìš”.  

1. IsaacGym ver.4 ì„¤ì¹˜ [isaac-gym íŽ˜ì´ì§€](https://developer.nvidia.com/isaac-gym)
2. `rsl-rl/` ìœ„ì¹˜ì—ì„œ `pip install -e .`
3. `legged-gym/` ìœ„ì¹˜ì—ì„œ `pip install -e .`
4. `ImportError: libpython3.8.so.1.0: cannot open shared object file: No such file or directory`
   - `export LD_LIBRARY_PATH=/home/jungyeon/anaconda3/envs/go2/lib`
5. `pip install tensorboard wandb`
6. `AttributeError: module 'distutils' has no attribute 'version'`
   - `pip install setuptools==59.5.0`
   - (ref) https://github.com/pytorch/pytorch/issues/69894
4. A1ìœ¼ë¡œ Rough terrain locomotion learning ì‹œìž‘(ì•„ëž˜ í‘œ ì°¸ê³ )

| option             | config           | critic_obs | actor_obs | memo                                               |
|--------------------|------------------|------------|-----------|:---------------------------------------------------|
| `--task=a1_base`   | A1RoughBaseCfg   | 45         | 45        | lin_velì„ ëº€ observation                             |
| `--task=a1_oracle` | A1RoughOracleCfg | 238        | 238       | true_lin_vel + privileged(d,h)                     |
| `--task=a1_waq`    | A1RoughBaseCfg   | 238        | 64        | est_lin_vel + privileged / obs_history(timestep 5) |

### Start **w/** docker
> ì´ repositoryë¥¼ ê¸°ë°˜ìœ¼ë¡œ docker ë¥¼ í†µí•´ ì‹œìž‘í•  ë•Œ ì•„ëž˜ì™€ ê°™ì´ ì§„í–‰í•´ì£¼ì„¸ìš”.
> CUDA 12.1 ì´ìƒì„ ì§€ì›í•˜ëŠ” ë“œë¼ì´ë²„ê°€ ì„¤ì¹˜ ë˜ì–´ìžˆì–´ì•¼ í•©ë‹ˆë‹¤.

1. IsaacGym ver.4 ë‹¤ìš´ë¡œë“œ [isaac-gym íŽ˜ì´ì§€](https://developer.nvidia.com/isaac-gym)
2. ë‹¤ìš´ë¡œë“œ ë°›ì€ `IsaacGym_Preview_4_Package.tar.gz` íŒŒì¼ì„ `asset/IsaacGym_Preview_4_Package.tar.gz` ë¡œ ì´ë™
3. ë‹¤ìŒ ëª…ë ¹ì–´ë¡œ ë„ì»¤ ë¹Œë“œ `docker build . -t dreamwaq/dreamwaq -f docker/Dockerfile  --build-arg UID=$(id -u) --build-arg GID=$(id -g)`
4. ë‹¤ìŒ ëª…ë ¹ì–´ë¡œ ë„ì»¤ ì‹¤í–‰ `docker run -ti --privileged -e DISPLAY=:0 -e TERM=xterm-256color -v /tmp/.X11-unix:/tmp/.X11-unix:ro --network host -v $PWD/dreamwaq:/home/user/dreamwaq --gpus all dreamwaq/dreamwaq /usr/bin/zsh`

### Command 

- training : `python train.py --task=[TASK_NAME] --headless`
  - `--headless`: ì‹œë®¬ë ˆì´í„° ì°½ì„ ë„ìš°ì§€ì•Šê³  í•™ìŠµ ì‹¤í–‰í•˜ëŠ” ì½”ë“œ. displayê°€ ì—†ëŠ” ì„œë²„ì—ì„œ ì‹¤í–‰ì‹œ ì¶”ê°€í•˜ëŠ” option.
- inferencing : `python play.py --task=[TASK_NAME] --load_run=[LOAD_FOLDER] --checkpoint=[CHECKPOINT_NUMBER]`
  - `[LOAD_FOLDER]`: `legged_gym/logs/[taskë³„ í´ë”]` ë‚´ë¶€ì— ìžˆëŠ” íŒŒì¼ ëª…. (ì˜ˆ) `Sep04_14-24-54_waq`
    - `[taskë³„ í´ë”]`: rough_a1/rough_a1_waq/rough_a1_est
  - `[CHECKPOINT_NUMBER]`: `[LOAD_FOLDER]`ì— ìžˆëŠ” **model_[NUMBER].pt** íŒŒì¼ì˜ ë²ˆí˜¸. (ì˜ˆ) `250`
  - ì™„ì„±ëœ command (ì˜ˆ) `python play.py --task=a1_waq --load_run=Sep04_14-24-54_waq --checkpoint=250`
  - í•˜ë‚˜ì˜ agentë¥¼ ê°€ê¹Œì´ì„œ ë³´ëŠ” inferencing code: `mini_test.py` (ì˜µì…˜ì€ `play.py`ì™€ ë™ì¼)
  - ê° inferencing scriptì— main loopì— ì¡°ì ˆí•˜ëŠ” ì˜µì…˜ë“¤ì´ ìžˆìœ¼ë‹ˆ ì°¸ê³ í•´ì„œ True/False ì¡°ì •.
- ë‹¤ë¥¸ ì»´í“¨í„°ì—ì„œ training ëœ **model_[NUMBER].pt** íŒŒì¼ì„ inferencingí•˜ê³  ì‹¶ë‹¤ë©´,
  - TRAINING **{@computer_A}** | INFERENCING **{@computer_B}**
    1. {@computer_B} `legged_gym/logs/[taskë³„ í´ë”]`ì— `FOLDER_NAME`ì´ë¼ëŠ” ìƒˆë¡œìš´ í´ë”ë¥¼ ë§Œë“  ë’¤,
    2. {@computer_B} `FOLDER_NAME`ì— {@computer_A}ì˜ **model_[NUMBER].pt íŒŒì¼**ì„ copy&paste
    2. {@computer_B} `python play.py --task=[TASK_NAME] --load_run=[FOLDER_NAME] --checkpoint=[NUMEBR]` ë¡œ ì‹¤í–‰.

## Main Code Structure


- í”„ë¡œì íŠ¸ ì½”ë“œë“¤ ì¤‘ ì¤‘ìš” íŒŒì¼ë“¤ì— ëŒ€í•œ ì„¤ëª…ìž…ë‹ˆë‹¤. í”„ë¡œì íŠ¸ì—ì„œ ì‚¬ìš©ëœ ë¡œë´‡ í”Œëž«í¼ê³¼ ì•Œê³ ë¦¬ì¦˜ ìœ„ì£¼ì˜ ì½”ë“œë“¤ì„ ì„ ì •í•˜ì˜€ìœ¼ë©°, ì‹¤í–‰ íŒŒì¼ëª… ì˜†ì— ìžˆëŠ” ì„¤ëª…ì„ ì°¸ê³ í•´ì£¼ì„¸ìš”.
   - ì‚¬ìš© ë¡œë´‡ í”Œëž«í¼(í™˜ê²½): A1
   - ì‚¬ìš© í•™ìŠµ ì•Œê³ ë¦¬ì¦˜: PPO

```
dreamwaq
â”‚
â”œâ”€â”€ legged_gym
â”‚   â”œâ”€â”€ legged_gym
â”‚   â”‚   â”œâ”€â”€ envs
â”‚   â”‚   â”‚   â”œâ”€â”€ __init__.py: í•™ìŠµ ì‹¤í–‰ì„ ìœ„í•œ í™˜ê²½ ë“±ë¡. task_registryì—ì„œ ì°¸ì¡°.
â”‚   â”‚   â”‚   â”œâ”€â”€ a1/a1_config.py: A1 í”Œëž«í¼ì— ë§žëŠ” ë³€ìˆ˜ í´ëž˜ìŠ¤. legged_robot_config.pyì˜ í´ëž˜ìŠ¤ ìƒì†.
â”‚   â”‚   â”‚   â””â”€â”€ base
â”‚   â”‚   â”‚        â”œâ”€â”€ legged_robot.py: locomotion taskë¥¼ ìœ„í•œ ê¸°ë³¸ í™˜ê²½ í´ëž˜ìŠ¤. LeggedRobot Class 
â”‚   â”‚   â”‚        â””â”€â”€ legged_robot_config.py: LeggedRobotì„ ìœ„í•œ ë³€ìˆ˜ í´ëž˜ìŠ¤. LeggedRobotCfg Class / LeggedRobotCfgPPO Class
â”‚   â”‚   â”œâ”€â”€ scripts
â”‚   â”‚   â”‚   â”œâ”€â”€ train.py: í•™ìŠµ ì‹¤í–‰ ë©”ì¸ ì½”ë“œ. wandb ì„¤ì • ì…‹íŒ…. (Command-training ì°¸ê³ )
â”‚   â”‚   â”‚   â”œâ”€â”€ play.py: í•™ìŠµ ì™„ë£Œ í›„ ë‹¤ì–‘í•œ ì§€í˜•ì—ì„œ ì—¬ëŸ¬ agentë“¤ì˜ ë³´í–‰ inference motionì„ í™•ì¸í•˜ëŠ” ì½”ë“œ.(Command-inference ì°¸ê³ )
â”‚   â”‚   â”‚   â””â”€â”€ mini_test.py:  í•™ìŠµ ì™„ë£Œ í›„ ë‹¤ì–‘í•œ ì§€í˜•ì—ì„œ ì—¬ëŸ¬ agentë“¤ì˜ ë³´í–‰ inference motionì„ í™•ì¸í•˜ëŠ” ì½”ë“œ.(Command-inference ì°¸ê³ )
â”‚   â”‚   â””â”€â”€ utils
â”‚   â”‚       â”œâ”€â”€ logger.py: play.pyë‚˜ mini_test.pyì—ì„œ ì‚¬ìš©ë˜ëŠ” matplotlib plotì„ ìœ„í•œ ì½”ë“œ.
â”‚   â”‚       â”œâ”€â”€ task_registry.py: envs/__init__.pyì— ë“±ë¡ëœ í•™ìŠµ í™˜ê²½ ì •ë³´ë¥¼ ê¸°ë°˜ìœ¼ë¡œ í™˜ê²½ê³¼ ì•Œê³ ë¦¬ì¦˜ ì—°ê²° ì‹¤í–‰.
â”‚   â”‚       â””â”€â”€ terrain.py: ë³´í–‰í•˜ëŠ” ì§€í˜• í´ëž˜ìŠ¤. LeggedRobotì—ì„œ ì°¸ì¡°.
â”‚   â”‚ 
â”‚   â””â”€â”€ resources/robots/a1: ë¡œë´‡ í”Œëž«í¼ì— ëŒ€í•œ ì •ë³´.(urdf&mesh)
â”‚
â””â”€â”€ rsl_rl
    â””â”€â”€ rsl_rl
        â”œâ”€â”€ algorithms
        â”‚   â””â”€â”€ ppo.py: PPO ì•Œê³ ë¦¬ì¦˜ ì½”ë“œ. actor_critic.pyì˜ Actor/Critic í´ëž˜ìŠ¤ ì‚¬ìš©.
        â”œâ”€â”€ modules
        â”‚   â””â”€â”€ actor_critic.py: Actor/Critic í´ëž˜ìŠ¤ ì½”ë“œ. 
        â”œâ”€â”€ runners
        â”‚   â””â”€â”€ on_policy_runner.py: ê°•í™”í•™ìŠµ ë©”ì¸ loop(learn í•¨ìˆ˜)ê°€ ìžˆëŠ” OnPolicyRunner í´ëž˜ìŠ¤ê°€ ìžˆëŠ” íŒŒì¼. 
        â”‚                            Base modelì€ OnPolicyRunner í´ëž˜ìŠ¤ë¡œ, DreamWaQ modelì€ OnPolicyRunnerWaq í´ëž˜ìŠ¤ë¡œ,
        â”‚                            Estnet modelì€ OnPolicyRunnerEst í´ëž˜ìŠ¤ë¡œ í•™ìŠµ ì½”ë“œê°€ ëŒì•„ê°.
        â”‚                            (ê°•í™”í•™ìŠµ main loop ì•ž ë‹¨ê³„[actor/critic network ì´ì „ ë‹¨ê³„]ì˜ ë³€í˜• ì—ë”°ë¼ í´ëž˜ìŠ¤ êµ¬ë¶„)
        â”œâ”€â”€ utils
        â”‚   â””â”€â”€ rms.py: CENetì˜ normal prior distribution í•™ìŠµì„ ìœ„í•œ Running Mean Std í´ëž˜ìŠ¤. 
        â””â”€â”€ vae
            â”œâ”€â”€ cenet.py: Context-Aided Estimator Network(CENet) í´ëž˜ìŠ¤.
            â””â”€â”€ estnet.py: ë¹„êµëª¨ë¸êµ°ì¸ Estimator í´ëž˜ìŠ¤.

```



## Result Graphs

ì•½ 1000 iteration ë™ì•ˆ í•™ìŠµ Reward Graph

![](./asset/two_models_rew.png)

### DreamWaQ model

- í•™ìŠµ í›„ 1ê°œì˜ robot agentì˜ state plot
  - 1í–‰: base state ì¤‘ x, y ë°©í–¥ì˜ ì†ë„ì™€ yaw ë°©í–¥ì˜ commandì™€ ì‹¤ì œ ì¸¡ì • ë¬¼ë¦¬ëŸ‰ plot
  - 2í–‰: CENetì„ í†µí•œ ì˜ˆì¸¡ëœ estimated ì†ë„ì™€ ì‹¤ì œ ì‹œë®¬ë ˆì´í„°ì—ì„œ ì¸¡ì •ëœ true ì†ë„ plot
  - 3í–‰: estimated ì†ë„ì™€ true ì†ë„ì˜ error plot
    - 1ì—´: x, y, z ë°©í–¥ì˜ ê° ì„±ë¶„ì˜ squared error
    - 2, 3ì—´, x, y ë°©í–¥ì˜ mean squared error

![](./asset/a1_waq_est_vel.png)

### Base model

- í•™ìŠµ í›„ 1ê°œì˜ robot agentì˜ state plot(DreamWaQì™€ ë‹¬ë¦¬, estimated ì†ë„ê°€ ì—†ìœ¼ë¯€ë¡œ plotí•œ ê·¸ëž˜í”„ê°€ ë‹¤ë¦„.)
  - 1í–‰: base state ì¤‘ x, y ë°©í–¥ì˜ ì†ë„ì™€ yaw ë°©í–¥ì˜ commandì™€ ì‹¤ì œ ì¸¡ì • ë¬¼ë¦¬ëŸ‰ plot
  - 2í–‰ 1ì—´/2ì—´: 1ê°œì˜ jointì˜ ìœ„ì¹˜ì™€ ì†ë„ 
  - 2í–‰ 3ì—´: base z ë°©í–¥ ì†ë„
  - 3í–‰ 1ì—´: 4ê°œ ë°œì˜ contact force
  - 3í–‰ 2/3ì—´: 1ê°œì˜ joint torque

![](./asset/a1_base_no_vel.png)

## Result Motions

### Walking Performance of a Reproduction Model in Different Terrains
- Smooth Slope / Rough Slope

![](./asset/1.gif)

- Stair Up / Stair Down

![](./asset/2.gif)

- Discrete / Mixed

![](./asset/3.gif)



### Comparative Analysis of Walking Motion Between the Reproduction Model and the Base Model

> small difference: naturalness of motion
> 
> big difference: foot stuck / unstable step

- Smooth Slope(small difference)

![](./asset/4.gif)

- Rough Slope(small difference)

![](./asset/5.gif)

- Stair Up(big difference)

![](./asset/6.gif)

- Stair Down(big difference)

![](./asset/7.gif)

- Discrete(big difference)

![](./asset/8.gif)


